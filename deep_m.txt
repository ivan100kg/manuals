Машинное обучение
	это область computer science, в которой машины учатся решать задачи, для 
	которых они не были запрограммированы непосредственно.

Глубокое обучение  
	это подмножество методов машинного обучения, главным       
	образом основанных на применении искусственных нейронных сетей, 
	которые представляют класс алгоритмов, подражающих человеческому мозгу.

Нейронные сети
	Обобщенная модель линейных моделей. В отличие от линейной модели, нейронная 
		сеть включает промежуточные слои.
	Нейронная сеть - это один или несколько весовых коэффициентов, на которые 
		можно умножить входные данные и получить прогноз
	Нейронные сети — это всего лишь наборы весовых коэффициентов, используемых 
		для вычисления функции ошибки.
	Нейронные сети изучают корреляцию 	
	В действительности нейронные сети ищут корреляцию между
		своими входным и выходным слоями.
	Нейронные сети стремятся отыскать прямую и косвенную корреляцию между
		входным и выходным слоями, которые определяются входным и выходным
		наборами данных соответственно.
	Любой данный набор весов оптимизируется в процессе обучения так, чтобы
		с его помощью из входных данных можно было получить то, что должно
		быть на выходе.
	

Корреляция - статистическая взаимосвязь двух или более случайных величин
	
Регуляризаця — прием, который заставляет веса с противоречивым давлением 
	опускаться в сторону 0, ключевое средство в борьбе против переобучения 
	нейронных сетей. Это подмножество методов, способствующих обобщению
	изучаемых моделей, часто за счет препятствования изучению мелких деталей.
	
Скрытые слои
	Если в ваших данных отсутствует явная корреляция, сгенерируйте промежуточные 
	данные, в которых такая корреляция имеется!
	Если входной набор данных не коррелирует с выходным, мы используем
	входной набор для создания промежуточного набора, имеющего корреляцию
	с выходным набором. Этот прием чем-то напоминает подтасовку.
	Создание корреляции см ниже

машинное обучение с учителем — это класс алгоритмов, обучающихся               
	предсказанию одного набора данных по другому	
		
обучение без учителя фактически сводится к делению набора данных на группы. 

параметрические алгоритмы имеют фиксированное число параметров

непараметрические алгоритмы выбирают число параметров, основываясь на данных.

-------------ML с Учителем------------------------------------------------
1. Прогноз:
	прогнозирование
	данные -> модель -> предсказание
	
	Прогноз, или предсказание, — это то, что возвращает нейронная сеть после
		получения входных данных	
		
	Прогноз — это взвешенная сумма входных значений. Алгоритм обучения
		придает дополнительную значимость входам, значения которых коррелируют
		с выходами, оказывая повышающее давление на соответствующие веса,
		и уменьшает значимость входов, не коррелирующих с выходами, оказывая 
		онижающее давление.
	
	# Чистая сеть
	input --> weight --> output
	игр   --> вес    --> победа?
	8.5   --> 0.1    --> 8.5 * 0.1 = 0.85 
	Прогноз =  вес * вход.
	
	# Чистая сеть с несколькими входами
	вход          веса  выход
	игр           0.1   \
	победа/пораж  0.2   - победа?
	борлельщиков  0.0   /
	Прогноз = каждый вход умножается на соответствующий ему вес, после чего 
		результаты суммируются. (Скалярное произведение векторов)
		
	# Чистая сеть с несколькими выходами
	вход           веса  выход
	             / 0.3   травмы?
	победа/пораж - 0.2   победа?
	             \ 0.9   печаль?
	Прогноз = каждый вход умножается на свой вес
	
	# Чистая сеть с несколькими входами и выходами
	вход           веса           выход
	игр			   0.1 0.1 -0.3   травмы?
	победа/пораж   0.1 0.2  0.0   победа?
	болельщиков    0.0 1.3  0.1   печаль?
	На каждый выход идет по 3 веса со входов
	Прогноз = Для каждого выхода вычисляется взвешенная сумма входов
	
	# Чистая сеть с несколькими входами и выходами + скрытые слои
	вход --> скрытый слой --> выход
	Учавствуют дополнительные веса в скрытых слоях
	def neural_network(input, weights):
		hid = input.dot(weights[0])
		pred = hid.dot(weights[l])
		return pred
-------------------------------------------------------------------------------
2. Сравнение:
	Сравнение позволяет оценить, насколько прогноз «промахнулся»
	Сравнение с истиной
		метод среднеквадратической ошибки
		error = (pred - mypred) ** 2                                            ошибка = (верное предсказание - наше предсказание) в квадрате           в итоге получаем всегда положительную ошибку
	
-------------------------------------------------------------------------------	
3. Обучение:
	Процесс обучения определяет, как изменить каждый вес, чтобы уменьшить ошибку
	На этом этапе модель меняет веса, учитывая ошибку и исх данные
	Градиентный спуск
	Метод обучения, позволяющий вычислить направление и величину изменения веса weight для изменения ошибки error

	weight =0.5  # вес
	goal_pred =0.8 # верный ответ
	input =0.5 # входящие данные
	for iteration in range(20): 
		pred = input * weight # наш прогноз
		error = (pred - goal_pred) ** 2 # ошибка методом **

		# переменная - как должен измениться вес
		direction_and_amount = (pred - goal_pred) * input 

		weight = weight - direction_and_amount 
		print("Error:" + str(error) + " Prediction:" + str(pred))

	Чистая ошибка (pred - goal_pred) определяет величину и направление промаха.

	Масштабирование, обращение знака, остановка - (Чистая ошибка * input) Эти три характеристики описывают общий эффект преобразования чистой ошибки в абсолютную величину изменения веса. Это необходимо для обхода трех основных крайних случаев, когда чистой ошибки недостаточно для вы­бора хорошей величины изменения веса.

	Остановка - эффект, обусловленный умноже­нием чистой ошибки на input.

	Обращение знака - умножение чистой ошибки на input меняет знак direction_and_amount, если input имеет отрицательное значение. Такое обращение знака гарантирует изменение веса в правильном направлении, даже когда input имеет отрицательное значение.

	Масштабирование - если input имеет большое значение, значит, и вес нужно изменить на большую величину.
	
	Метод обучения (поиск минимума ошибки) называется градиентным спуском.	
	Вы перемещаете значение веса в направлении, противоположном значению градиента, и приближаете ошибку к 0. То есть вы увеличиваете вес при отрицательном градиенте, и наоборот.

	---------градиентный спуск - обучение  для 1 входа и 1 выхода---------------
	weight = 0.0    # весовой коэф
	goal_pred = 0.8 # известные ответы
	input = 0.5     # входящие данные
	alpha = 0.01    # коэф для скорости коррекции веса(что бы не уйти в разброс)
	for iteration in range(4):
		pred = neural_network_11()				# прогноз для 11
		error = (pred - goal_pred) ** 2 		# ошибка
		delta = pred - goal_pred 				# чистая/нормализованная ошибка
		weight_delta = delta * input		 	# производная
		weight = weight - weight_delta * alpha 	# нов вес коррекция
		
		print("Error:" + str(error) + " Prediction:" + str(pred))
	-------------------------------------------------------------------
	------Обучение методом градиентного спускас несколькими входами----------
	# Все то же самое, немного различий в комментах, 
	weights = [0.1, 0.2, -0.1]
	toes =  [8.5 , 9.5, 9.9, 9.0]
	wlrec = [0.65, 0.8, 0.8, 0.9]
	nfans = [1.2 , 1.3, 0.5, 1.0]
	win_or_lose_binary = [1,1,0,1]
	
	goal_pred = win_or_lose_binary[0]
	input = [toes[0],wlrec[0],nfans[0]]
	alpha = 0.01
	
	pred = neural_network_m1(input,weights) # прогноз для m1
	error = (pred - know) ** 2
	delta = pred - know
	weight_deltas = ele_mul(input,delta) # умнож вектор(input) на скаляр(delta)
	for i in range(len(weights)):			# присваиваем новые веса
		weights[i] -= alpha * weight-deltas[i]
	-------------------------------------------------------------------------
	-----Обучение методом градиентного спуска с несколькими выходами---------
	weights = [0.3, 0.2, 0.9]
	wlrec = [0.65, 1.0, 1.0, 0.9]
	
	hurt = [0.1, 0.0, 0.0, 0.1]
	win = [ 1, 1, 0, 1]
	sad = [0.1, 0.0, 0.1, 0.2]
	
	input = wlrec[0]
	know = [hurt[0], win[0], sad[0]] # ответы (обуч данные)
	pred = neural_network_1m(input,weights) # 1m
	
	error = [0, 0, 0] # ошибки и чистые ошибки обраб-ся для каждого выхода
	delta = [0, 0, 0]
	for i in range(len(know)):
		error[i] = (pred[i] - know[i]) ** 2
		delta[i] = pred[i] - know[i]
		
	weight_deltas = ele_mul(delta,input) # умножаем вектор(delta) на скаляр(input)
	for i in range(len(weights)): # нов веса
		weights[i] -= (weight_deltas[i] * alpha) 	
	-------------------------------------------------------------------------
	---Обучение методом градиентного спуска с несколькими входами и выходами-
	# игр %победа # болельщики
	weights = [ [0.1, 0.1, -0.3],# травмы?
				[0.1, 0.2, 0.0], # победа?
				[0.0, 1.3, 0.1] ]# печаль?
				
	toes = [8.5, 9.5, 9.9, 9.0]
	wlrec = [0.65,,0.8, 0.8, 0.9]
	nfans = [1.2, 1.3, 0.5, 1.0]
	
	hurt = [0.1, 0.0, 0.0, 0.1]
	win [ 1, 1, 0, 1]
	sad [0.1, 0.0, 0.1, 0.2]
	
	alpha = 0.01
	input = [toes[0],wlrec[0],nfans[0]]
	know = [hurt[0], win[0], sad[0]]
	
	pred = neural_network_mm(input,weights) # mm
	
	error = [0, 0, 0]
	delta = [0, 0, 0]
	for i in range(len(know)):
		error[i] = (pred[i] - know[i]) ** 2
		delta = pred[i] - know[i]
	
	 def outer_prod(a, b): # создание матрицы из произведения векторов
...     out = np.zeros((len(a), len(b)))
...     for i in range(len(a)):
...             for j in range(len(b)):
...                     out[i][j] = a[i]*b[j]
...     return out

	weight_deltas = outer_prod(input,delta) # матрица изменений
	
	далее вычитаем из каждого веса изменение и умножаем на альфа	
	-------------------------------------------------------------------------
	----Стохастический градиентный спуск-------------------------------------
	метод позволяет выполнять обучение сразу на всем наборе данных.
	Он многократно перебирает все данные из набора, пока не найдет комбинацию 
	весов, которая хорошо прогнозирует все обучающие примеры.
	import numpy as np

	weights = np.array([0.0,0.0,0.0])
	lightning  = np.array([[1, 0, 0],  # красный
						   [1, 1, 0],  # красный+желтый
						   [0, 0, 1],  # зеленый
						   [0, 0, 2], # мигающий зеленый
						   [0, 1, 0]]) # желтый
	walk_or_stop = np.array([0, 0, 1, 1, 0]) # идти - 1, стоять - 0
	alpha = 0.01

	for i in range(800):
		total_error = 0 # ошибка обнуляется с каждой итерацией
		for j in range(len(walk_or_stop)):  # перебираем все наборы данных
			inpt = lightning[j]	            # вход
			goal_pred = walk_or_stop[j]     # обуч ответы
			pred = np.dot(inpt, weights)    # прогноз аля mm в стиле np
			error = (pred - goal_pred) ** 2 # ошибка
			total_error+=error				# общая ошибка всех наборов
			delta = pred - goal_pred		# чистая ошибка
			weights = weights - (alpha*(inpt*delta))
			print("Prediction:" + str(pred))
		print("Error:" + str(total_error) + "\n")

	# пробуем модель
	from neural import neural_network_m1
	
	inpt = [0, 1, 0]
	print("Пробую желтый : ", round(neural_network_m1(inpt, weights), 2),"%")
	-------------------------------------------------------------------------	

    Формула связи веса с ошибкой    
        error = ((input * weight) - goal_pred) ** 2
		
		Знак наклона дает нам направление, а крутизна - величину изменения.
		direction_and_amount = (pred - goal_pred) * input = -0.3025
		
		Производная определяет изменение одной переменной в зависимости от изменения другой
		Производная — это наклон прямой или кривой в данной точке. если нарисовать график функции, наклон линии графика в данной точке будет в точности отражать, «насколько одна переменная изменится при изменении другой»
		Она описывает связь между двумя переменными в функции и позволяет узнать, насколько изменится одна переменная при изменении другой. Это просто чувствительность одной переменной к изменению другой.
		Чувствительность может быть положительной (когда переменные изменяются в одном направлении), отрицательной (когда они изменяются в разных направлениях) и нулевой (когда изменение одной переменной никак не отражается на другой)
		В чем разница между ошибкой и производной от ошибки и веса? Ошибка определяет величину промаха. А производная определяет отношение между каждым весом и величиной промаха. Иначе говоря, производная говорит, какой вклад вносит в ошибку изменение веса
		
		Наша формула имеет U-образную форму на графике - 
		error по  Y
		weight по X
		начальный вес - точка в которой ошибка и dir_a_am != 0
		error = 0 - место касания с осью Х - это целевой вес где 
			direction_and_amount = 0
		слева -  direction_and_amount будет получаться отрицательным и чем дальше
			тем больше наклон, соответственно и значение
		справа - direction_and_amount > 0 ==> вес больше целевого
		касательная линия к графику в нач точке - это производная То есть
			касательная в этой точке подсказывает, насколько изменится ошибка при изменении веса 
			weight_delta — это наша производная
		Затем смещаем вес в направлении,противоположном производной, и получаем уменьшенную ошибку. Вот и все! Нейронная сеть сделала один шаг в обучении.
		
	Градиент - это вектор с производными, включает в себя все значения для 
		изменения весов в одном слое.  
--------------------------------------------------------------------------------

Создание корреляции
	цель — обучить эту сеть так, чтобы даже в отсутствие явной корреляции между
	входным и выходным наборами данных (lауег_0 и lауег_2) набор lауег_1,
	созданный из набора lауег_0, имел корреляцию с набором lауег_2.
	
	входной слой --> скрытый слой --> выходной слой
	layer_0      --> layer_1      --> layer_2

Обратное распростронение
	Определить, какие значения должны получаться в предыдущем слое, можно
		по значениям, которые должны получаться в следующем слое, умножив выход
		следующего слоя на матрицу весов между слоями. Таким способом последующие
		слои могут сообщать предыдущим, какой сигнал им нужен, чтобы
		в итоге выявить корреляцию с выходом.
 -----------------------------------------------------------------------------------
# первая глубокая нейронная сеть

# Эта функция преобразует отрицательные числа в 0
def relu(x):
    return (x > 0) * x # типа int(x>0) --> (1 или 0) * x

# Эта функция преобразует положительные числа в 1 иначе 0
def relu2deriv(output):
    return output > 0  # Возвращает 1, если output > 0; иначе возвращает 0

    alpha = 0.2     # коэф регулировки скор обуч
    hidden_size = 4 # размер скрытого слоя

    # сигналы светофора
    streetlights  = np.array([[1, 0,   0],  # красный
                              [1, 1,   0],  # красный+желтый
                              [0, 0,   1],  # зеленый
                              [0, 1,   0]]) # желтый

    # идти или стоять
    walk_vs_stop = np.array([[ 0, 0, 1, 0]]).T

    # рандомные веса для 3-х слоев------------------------------------------------------
    # random((a, b)) - возвращ матрицу a x b (стр х столб) от 0 до 1 float
    # матрицу умножаем на 2 и вычитаем 1 - в итоге получатся значения от -1 до 1
    np.random.seed(1)
    weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1 # веса между 0 и 1 слоем
    weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1 # веса между 1 и 2 слоем---

    for iteration in range(60):
        layer_2_error = 0 # общая ошибка выходного слоя
        for i in range(len(streetlights)):
            layer_0 = streetlights[i:i + 1]  # 1-ый слой(вход)
            layer_1 = relu(np.dot(layer_0, weights_0_1))  # 2-й слой(промеж)/prediction1/прогноз1, взвеш суммы первого слоя и весов_01, пропущ через relu, которая минусовые знач обнуляет
            layer_2 = np.dot(layer_1, weights_1_2)  # 3-й слой(выход)/prediction2/прогноз2, взвеш суммы второго слоя с весами_12

            # общ ошибка += сумма(вектор ошибок)
            layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i + 1]) ** 2) # ср.кв. ошибка(сумма всех ошибок) выходного слоя и прав ответов

            layer_2_delta = (layer_2 - walk_vs_stop[i:i + 1]) # чистая/нормализованая ошибка_3: слой3(он же прогноз) - прав ответ
            layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)  # взвеш сумма(чист ошибка_3 и веса_12.T(транспонированные) * слой_2

            weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)  # корректируем вес, масштабируем + на альфа
            weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)  # корректируем вес, масштабируем + на альфа
        if (iteration % 10 == 9):
            print("Error:" + str(layer_2_error))

    # --- пробуем
    layer_0 = np.array([0,0,1])
    layer_1 = relu(np.dot(layer_0, weights_0_1))
    layer_2 = np.dot(layer_1, weights_1_2)
    print("Светофор зеленый: идти? - {}%\n".format(layer_2[0] * 100))

# ----------------------------------------------------------------------------------

Упрощенная визуализация нейросети
				*  layer_2
				
				*  weights_1_2		матрица весов (x, y) имеет размеры
				*					строк - предыдущий слой
				*					столбцов - следующий слой
				*
									Итого можно упростить еще:
			 * * * *  layer_1			l2		*  		layer_2(выход)
										W1	weights_1_2(4x1)
			 * * * *					l1	 * * * *  	layer_1(1-ый скрытый)
			 * * * *  weights_0_1		W0	weights_0_1(3x4)
			 * * * *					l0	  * * *     layer_0(вход)
									Это архитектура нейронной сети.
			  * * *  layer_0 

Векторно-матричные умножения		
	вычисляет несколько взвешенных сумм, по
	числу элементов в векторе. Матрица должна иметь столько же строк, сколько
	элементов в векторе, чтобы, используя каждый столбец в матрице, можно
	было найти уникальную взвешенную сумму. То есть если матрица имеет четыре
	столбца, она сгенерирует четыре взвешенных суммы.
	
	l0 * W0 - Умножить вектор слоя l0 на весовую матрицу W0
	l1 * W1 - Умножить вектор слоя l1 на весовую матрицу W1
	
	l1 = relu(l0 * W0) - используем relu и век-мат умножение, получаем l1
	l2 = l1 * W1  - получение слоя l2
	
	l2 = relu(l0 * W0)* W1 - объединяем все в 1 формулу
	
	layer_2 = relu(layer_0.dot(weights_0_1).dot(weights_1_2)) - на Python

	

	



    

    

    
