Apache Kafka
    Системы обмена сообщениями по принципу «публикация/подписка»
    Распределенный журнал фиксации транзакций
    Распределенная платформа потоковой обработки
    
    Данные в Kafka хранятся долго, упорядоченно, доступны для чтения,
    могут использоваться для доп защиты от сбоев и ради повышения
    производительности.


Паттерн публикация/подписка 
    publish/subscribe (pub/sub) messaging
    отправитель(издатель) элемента данных(сообщения) направляет это сообщение
    не конретно потребителю(подписчику), а просто классифицирует сообщение.
    Потребитель(подписчик) подписывается на определенные классы сообщений.
    Брокер - центральный пункт публикации сообщений, включен для упрощения
    взаимодействий между издателем и подписчиком.

Сообщения/event и пакеты
    message - сообщение [массив байтов] которой включает несколько атрибутов  
    event   - JSON String null - тело сообщения
    key     - доп метаданные в сообщении, используется при
              необходимости лучше управлять записью сообщений в разделы
    offset  - доп метаданные в сообщении - непрерывно
              возрастающее int значение, смещение
    batch   - пакет/набор сообщений, относящихся к одному топику и разделу, 
              применяется для большей эффективности

Схемы
    Доп структура для сообщений, позволяет легко разбирать сообщения

Топики и разделы/Topic/Partition
    Топик   - сообщения в Kafka распределяются по топикам
    Раздел  - топики, в свою очередь, разбиваются на разделы(партиции)
    Stream  - поток данных, термин используется в рассмотрении топика

    partitons    consumers     store                              producers  
    -------------------------------------------------------------------------
    partition_0                0 1 2 3 4 5 6 7 8 9 10 <----------┐
    partition_1              / 0 1 2 3 4 5 6 7 8 9 <-------------┤
    partition_2  concume < --- 0 1 2 3 4 5 6 7 8 9 10 12 13 <----┤-<- produce
    partition_3              \ 0 1 2 3 4 5 6 7 8 9 10 12 13 14 <-┤
    partition_4                0 1 2 3 4 5 6 7 <-----------------┘

    после записи сообщения нельзя изменить/удалить

    Если записывать в один раздел, то очередность чтения сохраниться,
    иначе чтение сообщений происходит параллельно

Производители и потребители
    producer    - publisher/writer/производитель, генерирует нов сообщения
                  сообщения создаются для конкретного топика, по умолчанию
                  производитель будет равномерно поставлять сообщения во 
                  все разделы топика, но может в конкретный раздел, 
                  используя ключ.
    consumer    - subscriber/reader/потребитель читает сообщения.
                  Потребитель подписывается на один или более топиков и 
                  читает сообщения в порядке их создания в каждом разделе,
                  отслеживает какие сообщения были прочитаны, запоминая
                  смещение(offset), может приостанавливать и возобновлять
                  чтение благодаря этому.
    consumer groups
                - один или нескольких потребителей, объединившихся для 
                  обработки топика в группу. Организация в группы гарантирует 
                  чтение каждого раздела только одним членом группы

Брокеры и кластеры
    Broker_1    Broker_2    Broker_3        Пример 3 брокера, 2 топика по 3 партиции:
                                            1 брокер - лидер для partition_10 и partition_22
        Topic_1         Topic_2                        фолловер для partition_11 partition_12
        partition_10    partition_20                                partition_20 partition_21
        partition_11    partition_21        2 брокер - лидер для partition_11 и partition_21
        partition_12    partition_22                   фолловер для partition_10 partition_12
                                                                    partition_20 partition_22
                                            3 брокер - лидер для partition_12 и partition_20
                                                       фолловер для partition_10 partition_11
                                                                    partition_21 partition_22

    При падении одного из брокеров, если он был лидером - лидер назначается из фолловеров

    broker  - отдельный сервер Kafka - получает сообщения от производителей, 
              присваивает им смещения и записывает сообщения в дисковое 
              хранилище. Он также обслуживает потребители и отвечает на запросы
              выборки из разделов, возвращая опубликованные сообщения
    cluster - Брокеры Kafka предназначены для работы в составе кластера
    cluster controller 
            - контроллер, один из брокеров кластера, выбирается автоматически 
              из числа работающих членов кластера. Отвечает за административные
              операции, включая распределение разделов по брокерам, мониторинг
    leader  - ведущий брокер, которому принадлежит раздел, для каждого раздела,
              соединяется с producer для публикации сообщений, consumer также
              может получать сообщения с ведущего
    follower- брокер-последователь, которому принадлежит реплицированный
              (дублирующий) раздел от ведущего. consumer также может получать 
              сообщения с последователя
    настройки 
            - В настройки брокеров Kafka включается длительность хранения 
              топиков по умолчанию - или в течение определенного промежутка 
              времени (например, семь дней), или до достижения разделом
              определенного размера в байтах (например, 1 Гбайт). 
              Превысившие эти пределы сообщения становятся недействительными и 
              удаляются
    
    Обычно на один раздел топика вешаются 3 брокера, 1 лидер + 2 последователя
    А один брокер берет один раздел как лидер и два как последователь
    Количество разделов должно быть >= кол-во consumers

Почему Kafka
    Несколько производителей    - способность работать с несколькими производителями
                                  вне зависимости от того, используют они один топик
                                  или несколько
    Несколько потребителей      - способность читать любой один поток сообщений, не 
                                  мешая друг другу
    Сохранение информ на диске  - потребители не обязательно должны работать в режиме
                                  реального времени
    Масштабируемость            - любые объемы данных
    ...


Install
    Java      - 8+
    ZooKeeper - Apache ZooKeeper это централизованный сервис для хранения информации 
                о конфигурации, присвоения имен, обеспечения распределенной 
                синхронизации и предоставления группового обслуживания.
                Используется для хранения метаданных о кластере Kafka
                zoo.cfg - файл конфиг ZooKeeper
                myid    - id сервера, в zoo.cfg можно указывать ансамбль серверов
    KRaft     - протокол пришел на смену ZooKeeper, замена Zookeeper в роли хранилища
                метаданных, с целью упрощения развертывания Kafka-кластера, внутри
                пакета Kafka лежат конфиги KRaft
                config/kraft      - дир с настройками KRaft
                broker.properties - конфиг сервера, который действует как брокер,
                                    настройка топиков, разделов
                controller.prop   - конфиг сервера, который действует как контроллер
                                    управляет метадаными кластера, управляет лидерами
                server.properties - конфиг сервера, который и контроллер и брокер                
    Kafka     - брокер кафка
                broker.id - id брокера в пределах кластера
                Listeners - разделенный запятыми список URI
                zookeeper.connect - ZooKeeper(hostname, port, path)
                log.dirs - куда пишутся все сообщения
                num.partitions - кол-во разделов
                log.retention.ms - время хранения сообщений
                log.retention.bytes - кол-во макс хранимых байтов


Event-Driven Architecture
                                        consumers:
                                        Email-micro
     producer                         /
    Payment-micro --publish--> Topic <- SMS-micro
                                      \
                                        Push-micro

    все работает асинхронно
    если допустим Push-micro не успевает обрабатывать сообщения Kafka
    то можно просто создать consumer groups из таких одинаковых  сервисов Push-micro


Kafka CLI
    command line interface - работа с kafka через терминал
    просто запускаем скрипты из директории bin


Запуск 1 сервера Kafka
    bin                                 - директория со скриптами
    ./kafka-storage.sh random-uuid      - сгенерить id для kafka кластера
    ./kafka-storage.sh format -t <uuid> -c ../config/kraft/server.properties - формат логов
    ./kafka-server-start.sh ../config/kraft/server.properties                - старт сервера


Запуск на нескольких серверах
    создать файлы аналогичные config/kraft/server.properties под сервера
    изменяем в каждом файле:
        node.id     - id сервера в Kafka кластере, делаем уникальные для каждого сервера
        listeners   - список адрес:портов которые слушает kafka
                      поменять для каждого сервера порты:
                      PLAINTEXT://9092  - брокер
                      CONTROLLER://9093 - контроллер
                      следующий сервер допустим 9094 9095 и тд
        controller.quorum.votes
                    - управление лидерами, последователями при падениях серверов
                      1@localhost:9093  - id_сервера@url_контроллера
                      для трёх серверов будет так во всех файлах:
                      1@localhost:9093,2@localhost:9095,3@localhost:9097
                      если на разных серверах - прописываем ip
        advertused.listeners
                    - список адресов брокеров, может совпадать или быть другим для
                      клиентов, например внешним, далее соединяется с внутринним listeners
                      PLAINTEXT://9092 выставить во всех файлах свой порт если совпадает с 
                      listeners, если kafka на другом сервере - прописываем ip
        log.dirs    - директория для логов
                      меняем для каждого сервера свою директорию
                      /var/lib/kafka/logs/serv1/kraft-combined-logs

    запуск серверов:
        генерим uuid:
            ./kafka-storage.sh random-uuid - сгенерим id кластера IuLotyvvS-GX5jpwmZYXeQ
        формат логов для совместимости:
            ./kafka-storage.sh format -t IuLotyvvS-GX5jpwmZYXeQ -c ../config/kraft/serv1
            ./kafka-storage.sh format -t IuLotyvvS-GX5jpwmZYXeQ -c ../config/kraft/serv2
            ./kafka-storage.sh format -t IuLotyvvS-GX5jpwmZYXeQ -c ../config/kraft/serv3
        запуск серверов(в разных терминалах):
            ./kafka-server-start.sh ../config/kraft/serv1
            ./kafka-server-start.sh ../config/kraft/serv2
            ./kafka-server-start.sh ../config/kraft/serv3


Остановка сервера
    Не останавливаем ctrl+c(портеря данных, логи ...)
    1. останановка produsers, consumers
    2. остановка с пом терминала ./kafka-server-stop.sh

Логи/сообщения/занимаемое место кластера
    ./kafka-log-dirs.sh                     посмотреть логи
        --bootstrap-server localhost:9092   сервера(один из)
        --broker-list 3                     конкретно какой брокер(id)
        --topic-list my-topic               конкретно топик 
        --describe                          ставим обязательно - описание
    Вывод в консоль:
        "brokers": [
            {
                "broker": 3,                                    # id брокера
                "logDirs": [
                    {
                        "partitions": [
                            {
                                "partition": "my-topic-0",      # партиция
                                "size": 130153,                 # размер в байтах (это сообщения Kafka)-┐
                                "offsetLag": 0,                 # кол-во не прочитанных сообщений       |
                                "isFuture": false               # создан ли в будущем и не используется |
                            },                                                                          |
                            ... ещё 2 партиции                                                          |
                        ],                                                                              |
                        "error": null,                          # ошибки                                |
                        "logDir": "/path/to/kafka/logs"         # директория где хранятся логи          |
                    }                                                                                   |
                ]                                                                                       |
            }                                                                                           |
        ],                                                                                              |
        "version": 1                                            # версия                                |
                                                                                                        |
    На диске                                                                                            |
        /tmp/serv3/kraft-comb-logs/my-topic-0/                                                          |
        -rw-rw-r-- 1 ivanb ivanb 10485760 сен 19 11:43 00000000000000000000.index                       |
        -rw-rw-r-- 1 ivanb ivanb   130153 сен 19 11:43 00000000000000000000.log <-----------------------┘
        -rw-rw-r-- 1 ivanb ivanb 10485756 сен 19 11:43 00000000000000000000.timeindex
        -rw-rw-r-- 1 ivanb ivanb        8 сен 18 14:24 leader-epoch-checkpoint
        -rw-rw-r-- 1 ivanb ivanb       43 сен 18 14:24 partition.metadata
    Посмотреть занимаемое место
        du -sh /path/to/kafka/logs
        если на разных серверах - то можно скрипт сделать и посмотреть на каждом du -sh


Topic
    создать новый топик:
        запустить сервера
        ./kafka-topics.sh --create                                  создать  
                          --topic my-topic                          топик с именем my-topic
                          --partitions 3                            разделы количество, лучше делать
                                                                    >= кол-ва consumers, иначе парал-
                                                                    лельного чтения не будет
                          --replication-factor 3                    кол-во копий каждого раздела <= кол-во серверов
                                                                    одна в лидере +остальные в
                                                                    репликах лучше делать = кол-во серверов
                          --bootstrap-server host:9092,host:9094    список брокеров в кластере, рекомендуется
                                                                    указывать хотя бы 2(один мало, вдруг недоступен)
    посмотреть топики:
        ./kafka-topics.sh --list --bootstrap-server host:9092       посмотреть топики, указываем один
                                                                    из брокеров кластера
        ./kafka-topics.sh --describe --bootstrap-server host:9092   детальная информация о топиках
                                                                    partition : 0   - раздел
                                                                    Leader: 1       - лидер раздела
                                                                    Replicas: 1,2,3 - копии на серверах
                                                                    Isr: 1,2,3      - синхронизация серверов
    изменить топик:
        изменить количество разделов
        kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic --partitions 16
    удалить топик:
        включить настройку, если выключена delete.topic.enable=true
        ./kafka-topics.sh --delete --topic my-topic --bootstrap-server host:9092 - удалить топик my-topic

Producer
    Создать сообщение через CLI
        ./kafka-console-producer.sh 
            --bootstrap-server localhost:9092   сервера
            --topic my-topic                    топик в который будем публиковать
            --property "parse.key=true"         если хотим слать сообщения с ключом(в один раздел)
            --property "key.separator=:"        обозначение разделителя для ключа:зачения
        далее переходим в интеррактивный режим - пишем через терминал сообщения + Enter в my-topic
            >hello          отправить без ключа
            >huid:hello     отправить с ключём в один раздел
                                                                    
    Что должен делать producer:
        1. publish   - публикация событий на Kafka Broker
        2. serialize - сериализовать сообщение под нужный тип данных, также можно сериализовать
                       ключ под его тип данных. Например String для ключа, JSON для сообщения
        3. определять топик
        4. определять раздел(партицию)(если передается ключ)

    Попадание в один раздел по ключу по примеру 3-х партиций:
        partition = hash("my-key") % 3      Kafka применяет хеш-функцию к значению ключа
        Таким образом определится один из трёх разделов и сообщения с одинаковым ключём
        попадают в одну партицию

    Можно отправлять сообщения в Kafka как синхронные(ждать подтверждения с Kafka Broker)
    так и асинхронные(не ждать подтверждения, а слать сообщения, а при приходе подтверждения - обработать)
        Browser Mobile                       /
               ^                            /
         login | HTTP-request/responce     /
               v                          /
        Auth Mecroservice       отправка /
               ^ Kafka Template --------------> Kafka
               |  (Producer)    <-------------- Broker
               |                подтверждение
               v
            Database


Consumer
    Прочитать сообщение с помощью CLI
        ./kafka-console-consumer.sh 
            --bootstrap-server localhost:9092,localhost:9094    сервера
            --topic mytopic                                     топик для чтения
            --from-beginning                                    печать все сообщения сначала
            --property "print.key=true"                         печатать ключ и сообщение
            --group <your-group-id>                             для чтения группой(каждый читает сообщение 1 раз)
        
Spring Boot Consumer
    Producer ---------> Broker: Topic[][][][] ---------> Consumer
              publish      store               consume
    
    Если Consumer один - то чтение идет с разных разделов
    Если сделать 3 реплики Consumer - то в случае если разделов 3 - читать будет каждый 1 раздел
    Это называется ConsumerGroup


------------ Project workframe -----------------
Hierarchy
    ├── config
    │   └── KafkaConfig.java
    ├── consumer
    │   ├── MedRecordStatusChangedConsumer.java
    │   └── PersonUUIDChangeConsumer.java
    ├── producer
    │   └── EgiszSendingProducer.java
    └── topics
        └── KafkaTopic.java

Dependencies
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka-test</artifactId>
        <scope>test</scope>
    </dependency>
    <!-- эта зависимость возможно не нужна -->
    <dependency>    
        <groupId>com.fasterxml.jackson.core</groupId>
        <artifactId>jackson-databind</artifactId>
    </dependency> 

application.properties
    spring.kafka.producer.bootstrap-servers=192.168.1.66:9092,192.168.1.66:9094
    spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
    spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
    spring.kafka.producer.acks=all
    spring.kafka.producer.retries=10
    spring.kafka.producer.properties.retry.backoff.ms=1000
    spring.kafka.producer.properties.delivery.timeout.ms=20000
    spring.kafka.producer.properties.linger.ms=0
    spring.kafka.producer.properties.request.timeout.ms=10000
    spring.kafka.producer.properties.max.in.flight.requests.per.connection=5
    spring.kafka.producer.properties.enable.idempotence=true

KafkaConfig.java
    // Общий конфиг для продюссеров и консьюмеров 
    @Configuration
    public class KafkaConfig {
        @Value("${spring.kafka.producer.bootstrap-servers}")
        private String bootstrapServers;
        @Value("${spring.kafka.producer.key-serializer}")
        private String keySerializer;
        @Value("${spring.kafka.producer.value-serializer}")
        private String valueSerializer;
        @Value("${spring.kafka.producer.acks}")
        private String acks;
        @Value("${spring.kafka.producer.retries}")
        private String retries;
        @Value("${spring.kafka.producer.properties.retry.backoff.ms}")
        private String retryBackoff;
        @Value("${spring.kafka.producer.properties.delivery.timeout.ms}")
        private String deliveryTimeout;
        @Value("${spring.kafka.producer.properties.linger.ms}")
        private String linger;
        @Value("${spring.kafka.producer.properties.request.timeout.ms}")
        private String requestTimeout;
        @Value("${spring.kafka.producer.properties.max.in.flight.requests.per.connection}")
        private String inFlightRequests;
        @Value("${spring.kafka.producer.properties.enable.idempotence}")
        private String idempotence;

        // producers config - фабрики и KafkaTemplate для продюссеров в проекте
        @Bean
        ProducerFactory<String, FirstDTO> firstProducerFactory() {      // 1-я фабрика для создания KafkaTemplate
            return new DefaultKafkaProducerFactory<>(producerConfig()); // общий конфиг
        }

        @Bean
        KafkaTemplate<String, FirstDTO> firstKafkaTemplate() {          // KafkaTemplate для отправки сообщений в топик
            return new KafkaTemplate<>(firstProducerFactory());         // для producer-1
        }

        @Bean
        ProducerFactory<String, SecondDTO> secondProducerFactory() {    // 2-я фабрика для создания KafkaTemplate
            return new DefaultKafkaProducerFactory<>(producerConfig()); // общий конфиг
        }

        @Bean
        KafkaTemplate<String, SecondDTO> secondKafkaTemplate() {        // KafkaTemplate для отправки сообщений в топик
            return new KafkaTemplate<>(secondProducerFactory());        // для producer-2 ...
        }

        // общий конфиг продюссеров
        private Map<String, Object> producerConfig() {
            Map<String, Object> config = new HashMap<>();
            config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
            config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
            config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
            config.put(ProducerConfig.ACKS_CONFIG, acks);
            config.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoff);
            config.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, deliveryTimeout);
            config.put(ProducerConfig.LINGER_MS_CONFIG, linger);
            config.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, requestTimeout);
            config.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, inFlightRequests);
            config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, idempotence);
            return config;
        }

        // consumer config - фабрики и настройки для консьюмеров в проекте
        @Bean
        ConsumerFactory<String, ThirdDTO> firstConsumerFactory() {
            return new DefaultKafkaConsumerFactory<>(consumerConfig("consumer-group-1", ThirdDTO.class.getName()));
        }

        @Bean
        ConcurrentKafkaListenerContainerFactory<String, ThirdDTO> firstKafkaListenerContainerFactory() {
            ConcurrentKafkaListenerContainerFactory<String, ThirdDTO> factory = new ConcurrentKafkaListenerContainerFactory<>();
            factory.setConsumerFactory(firstConsumerFactory());
            return factory;
        }

        @Bean
        ConsumerFactory<String, FourthDTO> secondConsumerFactory() {
            return new DefaultKafkaConsumerFactory<>(consumerConfig("consumer-group-2", FourthDTO.class.getName()));
        }

        @Bean
        ConcurrentKafkaListenerContainerFactory<String, FourthDTO> secondKafkaListenerContainerFactory() {
            ConcurrentKafkaListenerContainerFactory<String, FourthDTO> factory = new ConcurrentKafkaListenerContainerFactory<>();
            factory.setConsumerFactory(secondConsumerFactory());
            return factory;
        }

        // конфиг для всех консьюмеров, отличается параметрами
        private Map<String, Object> consumerConfig(String groupId, String className) {
            Map<String, Object> config = new HashMap<>();
            config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
            config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
            config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer.class);
            config.put(ErrorHandlingDeserializer.VALUE_DESERIALIZER_CLASS, JsonDeserializer.class);
            config.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
            config.put(JsonDeserializer.TRUSTED_PACKAGES, "*");
            config.put(JsonDeserializer.VALUE_DEFAULT_TYPE, className);
            config.put(JsonDeserializer.USE_TYPE_INFO_HEADERS, "false");
            return config;
        }
    }

KafkaTopic.java
    // настраиваем любое кол-во топиков, если топиков ещё нет - то они будут созданы
    // если топики существуют - ничего не происходит
    @Configuration
    public class KafkaTopic {
        @Bean
        NewTopic createFirstTopic() {
            return TopicBuilder.name("topic-1")                     // имя топика
                    .partitions(3)                                  // кол-во пратиций
                    .replicas(3)                                    // кол-во реплик
                    .configs(Map.of("min.insync.replicas", "2"))    // минимум синхронизированных реплик с лидером
                    .build();
        }

        @Bean
        NewTopic createSecondTopic() {
            return TopicBuilder.name("topic-2")
                    .partitions(3)
                    .replicas(3)
                    .configs(Map.of("min.insync.replicas", "2"))
                    .build();
        }
    }

                // синхронная отправка(когда нужно дождаться ответа перед тем как послать след сообщение)
                SendResult<String, ProductCreatedEvent> result = 
                    kafkaTemplate.send("product-created-event", productId, productCreatedEvent).get();
                logger.info("Ok: {}", result.getRecordMetadata());

                return productId;

Получение acknowledgment
    Варианты конфигурации:
        1. Ждать acknowledgement от всех insync реплик  - spring.kafka.producer.acks=all
        2. Не получать acknowledgement                  - spring.kafka.producer.acks=0
        3. Получать только от Leader(default)           - spring.kafka.producer.acks=1
    Если acknowledgment не приходит от лидера или при all не приходит от всех insync реплик, 
    то Producer начинает делать retry:
        Либо делает retry в течение 2 мин, либо делаем максимальное кол-во retry 2147483647, либо указываем
        вручную кол-во retry, интервал, время попыток:
            spring.kafka.producer.retries=10 (default 2147483647 максимальное кол-во retry)
            spring.kafka.producer.properties.retry.backoff.ms=1000  (default 100 интервал отправки сообщений)
            spring.kafka.producer.properties.delivery.timeout.ms=60000 (default 120000 время попыток)
            spring.kafka.producer.properties.linger.ms=0 (сколько по времени накапливаем сообщ, потом шлем батчем)
            spring.kafka.producer.properties.request.timeout.ms=30000 (как долго prducer ждет ответа от брокера)
            spring.kafka.producer.properties.max.in.flight.requests.per.connection=5 (макс 5 сообщений без ответа)
            spring.kafka.producer.properties.enable.idempotence=true (Idempotent Producer - ниже описано)
            !!! delivery.timeout.ms >= linger.ms + request.timeout.ms
    Ошибки типа error acknowlegement:
        1. Retryable error - временная проблема, может быть решена повтором(retry), если
           например реплика упала
        2. Non-Retryable error - постоянная ошибка - не может быть решена повтором, если
           например превышен допустимый размер сообщения

Idempotent Producer
    При послылке сообщения и сохранении его в топик, допустим валится acknowledgment
    Делается retry но сообщение НЕ сохраняется ещё раз, а возвращается acknowledgment
    по умолчанию true, но рекумендуется указать явно 
    включить конфиг через properties или мэпку
        spring.kafka.producer.properties.enable.idempotence=true
        config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true)


            config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer.class); // скипает SerializationException
                                                                                                            если допустим пришла строка, выскакивает
                                                                                                            SerializationException 1 раз и пропускается
                                                                                                            переходит к следующей ячейке
            config.put(ErrorHandlingDeserializer.VALUE_DESERIALIZER_CLASS, JsonDeserializer.class);      // обрабатывает JSON
            config.put(ConsumerConfig.GROUP_ID_CONFIG, environment.getProperty("spring.kafka.consumer.group-id"));
            config.put(JsonDeserializer.TRUSTED_PACKAGES, environment.getProperty("spring.kafka.consumer.properties.spring.json.trusted.packages"));

            return new DefaultKafkaConsumerFactory<>(config);
        }

        @Bean
        ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(ConsumerFactory<String, Object> consumerFactory) {
            ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
            factory.setConsumerFactory(consumerFactory);

            return factory;
        }
    }