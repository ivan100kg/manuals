Apache Kafka
    Системы обмена сообщениями по принципу «публикация/подписка»
    Распределенный журнал фиксации транзакций
    Распределенная платформа потоковой обработки
    
    Данные в Kafka хранятся долго, упорядоченно, доступны для чтения,
    могут использоваться для доп защиты от сбоев и ради повышения
    производительности.


Паттерн публикация/подписка 
    publish/subscribe (pub/sub) messaging
    отправитель(издатель) элемента данных(сообщения) направляет это сообщение
    не конретно потребителю(подписчику), а просто классифицирует сообщение.
    Потребитель(подписчик) подписывается на определенные классы сообщений.
    Брокер - центральный пункт публикации сообщений, включен для упрощения
    взаимодействий между издателем и подписчиком.

Сообщения/event и пакеты
    message - сообщение [массив байтов] которой включает несколько атрибутов  
    event   - JSON String null - само так сказать тело сообщения
    key     - доп метаданные в сообщении, используется при
              необходимости лучше управлять записью сообщений в разделы
    offset  - доп метаданные в сообщении - непрерывно
              возрастающее int значение, смещение
    batch   - пакет/набор сообщений, относящихся к одному топику и разделу, 
              применяется для большей эффективности

Схемы
    Доп структура для сообщений, позволяет легко разбирать сообщения

Топики и разделы/Topic/Partition
    Топик   - сообщения в Kafka распределяются по топикам
    Раздел  - топики, в свою очередь, разбиваются на разделы
    Stream  - поток данных, термин используется в рассмотрении топика

                Топик
    Раздел_0  0 1 2 3 4 5 6 7 8 9 10 <----------┐
    Раздел_1  0 1 2 3 4 5 6 7 8 9 <-------------┤
    Раздел_2  0 1 2 3 4 5 6 7 8 9 10 12 13 <----┤--- операция записи
    Раздел_3  0 1 2 3 4 5 6 7 8 9 10 12 13 14 <-┤
    Раздел_4  0 1 2 3 4 5 6 7 <-----------------┘

    после записи сообщения нельзя изменить/удалить

Производители и потребители
    producer    - publisher/writer/производитель, генерирует нов сообщения
                  сообщения создаются для конкретного топика, по умолчанию
                  производитель будет равномерно поставлять сообщения во 
                  все разделы топика, но может в конкретный раздел, 
                  используя ключ.
    consumer    - subscriber/reader/потребитель читает сообщения.
                  Потребитель подписывается на один или более топиков и 
                  читает сообщения в порядке их создания в каждом разделе,
                  отслеживает какие сообщения были прочитаны, запоминая
                  смещение(offset), может приостанавливать и возобновлять
                  чтение благодаря этому.
    consumer groups
                - один или нескольких потребителей, объединившихся для 
                  обработки топика в группу. Организация в группы гарантирует 
                  чтение каждого раздела только одним членом группы

Брокеры и кластеры
    broker  - отдельный сервер Kafka - получает сообщения от производителей, 
              присваивает им смещения и записывает сообщения в дисковое 
              хранилище. Он также обслуживает потребители и отвечает на запросы
              выборки из разделов, возвращая опубликованные сообщения
    cluster - Брокеры Kafka предназначены для работы в составе кластера
    cluster controller 
            - контроллер, один из брокеров кластера, выбирается автоматически 
              из числа работающих членов кластера. Отвечает за административные
              операции, включая распределение разделов по брокерам, мониторинг
    leader  - ведущий брокер, которому принадлежит раздел, для каждого раздела,
              соединяется с producer для публикации сообщений, consumer также
              может получать сообщения с ведущего
    follower- брокер-последователь, которому принадлежит реплицированный
              (дублирующий) раздел от ведущего. consumer также может получать 
              сообщения с последователя
    настройки 
            - В настройки брокеров Kafka включается длительность хранения 
              топиков по умолчанию - или в течение определенного промежутка 
              времени (например, семь дней), или до достижения разделом
              определенного размера в байтах (например, 1 Гбайт). 
              Превысившие эти пределы сообщения становятся недействительными и 
              удаляются

Почему Kafka
    Несколько производителей    - способность работать с несколькими производителями
                                  вне зависимости от того, используют они один топик
                                  или несколько
    Несколько потребителей      - способность читать любой один поток сообщений, не 
                                  мешая друг другу
    Сохранение информ на диске  - потребители не обязательно должны работать в режиме
                                  реального времени
    Масштабируемость            - любые объемы данных
    ...


Install
    Java      - 8+
    ZooKeeper - Apache ZooKeeper это централизованный сервис для хранения информации 
                о конфигурации, присвоения имен, обеспечения распределенной 
                синхронизации и предоставления группового обслуживания.
                Используется для хранения метаданных о кластере Kafka
                zoo.cfg - файл конфиг ZooKeeper
                myid    - id сервера, в zoo.cfg можно указывать ансамбль серверов
    Kafka     - брокер кафка
                broker.id - id брокера в пределах кластера
                Listeners - разделенный запятыми список URI
                zookeeper.connect - ZooKeeper(hostname, port, path)
                log.dirs - куда пишутся все сообщения
                num.partitions - кол-во разделов
                log.retention.ms - время хранения сообщений
                log.retention.bytes - кол-во мас хранимых байтов


Event-Driven Architecture
                                        consumers:
                                        Email-micro
     producer                         /
    Payment-micro --publish--> Topic <- SMS-micro
                                      \
                                        Push-micro

    все работает асинхронно
    если допустим Push-micro не успевает обрабатывать сообщения Kafka
    то можно просто создать consumer groups из таких одинаковых  сервисов Push-micro
