Apache Kafka
    Системы обмена сообщениями по принципу «публикация/подписка»
    Распределенный журнал фиксации транзакций
    Распределенная платформа потоковой обработки
    
    Данные в Kafka хранятся долго, упорядоченно, доступны для чтения,
    могут использоваться для доп защиты от сбоев и ради повышения
    производительности.


Паттерн публикация/подписка 
    publish/subscribe (pub/sub) messaging
    отправитель(издатель) элемента данных(сообщения) направляет это сообщение
    не конретно потребителю(подписчику), а просто классифицирует сообщение.
    Потребитель(подписчик) подписывается на определенные классы сообщений.
    Брокер - центральный пункт публикации сообщений, включен для упрощения
    взаимодействий между издателем и подписчиком.

Сообщения/event и пакеты
    message - сообщение [массив байтов] которой включает несколько атрибутов  
    event   - JSON String null - само так сказать тело сообщения
    key     - доп метаданные в сообщении, используется при
              необходимости лучше управлять записью сообщений в разделы
    offset  - доп метаданные в сообщении - непрерывно
              возрастающее int значение, смещение
    batch   - пакет/набор сообщений, относящихся к одному топику и разделу, 
              применяется для большей эффективности

Схемы
    Доп структура для сообщений, позволяет легко разбирать сообщения

Топики и разделы/Topic/Partition
    Топик   - сообщения в Kafka распределяются по топикам
    Раздел  - топики, в свою очередь, разбиваются на разделы
    Stream  - поток данных, термин используется в рассмотрении топика

                Топик
    Раздел_0  0 1 2 3 4 5 6 7 8 9 10 <----------┐
    Раздел_1  0 1 2 3 4 5 6 7 8 9 <-------------┤
    Раздел_2  0 1 2 3 4 5 6 7 8 9 10 12 13 <----┤--- операция записи
    Раздел_3  0 1 2 3 4 5 6 7 8 9 10 12 13 14 <-┤
    Раздел_4  0 1 2 3 4 5 6 7 <-----------------┘

    после записи сообщения нельзя изменить/удалить

Производители и потребители
    producer    - publisher/writer/производитель, генерирует нов сообщения
                  сообщения создаются для конкретного топика, по умолчанию
                  производитель будет равномерно поставлять сообщения во 
                  все разделы топика, но может в конкретный раздел, 
                  используя ключ.
    consumer    - subscriber/reader/потребитель читает сообщения.
                  Потребитель подписывается на один или более топиков и 
                  читает сообщения в порядке их создания в каждом разделе,
                  отслеживает какие сообщения были прочитаны, запоминая
                  смещение(offset), может приостанавливать и возобновлять
                  чтение благодаря этому.
    consumer groups
                - один или нескольких потребителей, объединившихся для 
                  обработки топика в группу. Организация в группы гарантирует 
                  чтение каждого раздела только одним членом группы

Брокеры и кластеры
    broker  - отдельный сервер Kafka - получает сообщения от производителей, 
              присваивает им смещения и записывает сообщения в дисковое 
              хранилище. Он также обслуживает потребители и отвечает на запросы
              выборки из разделов, возвращая опубликованные сообщения
    cluster - Брокеры Kafka предназначены для работы в составе кластера
    cluster controller 
            - контроллер, один из брокеров кластера, выбирается автоматически 
              из числа работающих членов кластера. Отвечает за административные
              операции, включая распределение разделов по брокерам, мониторинг
    leader  - ведущий брокер, которому принадлежит раздел, для каждого раздела,
              соединяется с producer для публикации сообщений, consumer также
              может получать сообщения с ведущего
    follower- брокер-последователь, которому принадлежит реплицированный
              (дублирующий) раздел от ведущего. consumer также может получать 
              сообщения с последователя
    настройки 
            - В настройки брокеров Kafka включается длительность хранения 
              топиков по умолчанию - или в течение определенного промежутка 
              времени (например, семь дней), или до достижения разделом
              определенного размера в байтах (например, 1 Гбайт). 
              Превысившие эти пределы сообщения становятся недействительными и 
              удаляются
    
    Обычно на один раздел топика вешаются 3 брокера, 1 лидер + 2 последователя
    А один брокер берет один раздел как лидер и два как последователь
    Количество разделов должно быть >= кол-во consumers

Почему Kafka
    Несколько производителей    - способность работать с несколькими производителями
                                  вне зависимости от того, используют они один топик
                                  или несколько
    Несколько потребителей      - способность читать любой один поток сообщений, не 
                                  мешая друг другу
    Сохранение информ на диске  - потребители не обязательно должны работать в режиме
                                  реального времени
    Масштабируемость            - любые объемы данных
    ...


Install
    Java      - 8+
    ZooKeeper - Apache ZooKeeper это централизованный сервис для хранения информации 
                о конфигурации, присвоения имен, обеспечения распределенной 
                синхронизации и предоставления группового обслуживания.
                Используется для хранения метаданных о кластере Kafka
                zoo.cfg - файл конфиг ZooKeeper
                myid    - id сервера, в zoo.cfg можно указывать ансамбль серверов
    KRaft     - протокол пришел на смену ZooKeeper, замена Zookeeper в роли хранилища
                метаданных, с целью упрощения развертывания Kafka-кластера, внутри
                пакета Kafka лежат конфиги KRaft
                config/kraft      - дир с настройками KRaft
                broker.properties - конфиг сервера, который действует как брокер,
                                    настройка топиков, разделов
                controller.prop   - конфиг сервера, который действует как контроллер
                                    управляет метадаными кластера, управляет лидерами
                server.properties - конфиг сервера, который и контроллер и брокер                
    Kafka     - брокер кафка
                broker.id - id брокера в пределах кластера
                Listeners - разделенный запятыми список URI
                zookeeper.connect - ZooKeeper(hostname, port, path)
                log.dirs - куда пишутся все сообщения
                num.partitions - кол-во разделов
                log.retention.ms - время хранения сообщений
                log.retention.bytes - кол-во мас хранимых байтов


Event-Driven Architecture
                                        consumers:
                                        Email-micro
     producer                         /
    Payment-micro --publish--> Topic <- SMS-micro
                                      \
                                        Push-micro

    все работает асинхронно
    если допустим Push-micro не успевает обрабатывать сообщения Kafka
    то можно просто создать consumer groups из таких одинаковых  сервисов Push-micro


Kafka CLI
    command line interface - работа с kafka через терминал
    просто запускаем скрипты из директории bin


Запуск 1 сервера Kafka
    bin                                 - директория со скриптами
    ./kafka-storage.sh random-uuid      - сгенерить id для kafka кластера
    ./kafka-storage.sh format -t <uuid> -c ../config/kraft/server.properties - формат логов
    ./kafka-server-start.sh ../config/kraft/server.properties                - старт сервера


Запуск на нескольких серверах
    создать файлы аналогичные config/kraft/server.properties под сервера
    изменяем в каждом файле:
        node.id     - id сервера в Kafka кластере, делаем уникальные для каждого сервера
        listeners   - список адрес:портов которые слушает kafka
                      поменять для каждого сервера порты:
                      PLAINTEXT://9092  - брокер
                      CONTROLLER://9093 - контроллер
                      следующий сервер допустим 9094 9095 и тд
        controller.quorum.votes
                    - управление лидерами, последователями при падениях серверов
                      1@localhost:9093  - id_сервера@url_контроллера
                      для трёх серверов будет так во всех файлах:
                      1@localhost:9093,2@localhost:9095,3@localhost:9097
        advertused.listeners
                    - список адресов брокеров, может совпадать или быть другим для
                      клиентов, например внешним, далее соединяется с внутринним listeners
                      PLAINTEXT://9092 выставить во всех файлах свой порт если совпадает с 
                      listeners, либо какой-то свой url
        log.dirs    - директория для логов
                      меняем для каждого сервера свою директорию
                      /tmp/serv1/kraft-combined-logs
    запуск серверов:
        генерим uuid:
            ./kafka-storage.sh random-uuid - сгенерим id кластера IuLotyvvS-GX5jpwmZYXeQ
        формат логов для совместимости:
            ./kafka-storage.sh format -t IuLotyvvS-GX5jpwmZYXeQ -c ../config/kraft/serv1
            ./kafka-storage.sh format -t IuLotyvvS-GX5jpwmZYXeQ -c ../config/kraft/serv2
            ./kafka-storage.sh format -t IuLotyvvS-GX5jpwmZYXeQ -c ../config/kraft/serv3
        запуск серверов(в разных терминалах):
            ./kafka-server-start.sh ../config/kraft/serv1
            ./kafka-server-start.sh ../config/kraft/serv2
            ./kafka-server-start.sh ../config/kraft/serv3


Остановка сервера
    Не останавливаем ctrl+c(портеря данных, логи ...)
    1. останановка produsers, consumers
    2. остановка с пом терминала ./kafka-server-stop


Topic
    создать новый топик:
        запустить сервера
        ./kafka-topics.sh --create                                  создать  
                          --topic my-topic                          топик с именем my-topic
                          --partitions 3                            разделы количество, лучше делать
                                                                    >= кол-ва consumers, иначе парал-
                                                                    лельного чтения не будет
                          --replication-factor 3                    кол-во копий каждого раздела
                                                                    одна в лидере +остальные в
                                                                    репликах(не больше колва серверов) 
                          --bootstrap-server host:9092,host:9094    список брокеров в кластере, можно
                                                                    указывать хотя бы 2
    посмотреть топики:
        ./kafka-topics.sh --list --bootstrap-server host:9092       посмотреть топики, указываем один
                                                                    из брокеров кластера
        ./kafka-topics.sh --describe --bootstrap-server host:9092   детальная информация о топиках
                                                                    partition : 0   - раздел
                                                                    Leader: 1       - лидер раздела
                                                                    Replicas: 1,2,3 - копии на серверах
                                                                    Isr: 1,2,3      - синхронизация серверов
    изменить топик:
        изменить количество разделов
        kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic --partitions 16
    удалить топик:
        включить настройку, если выключена delete.topic.enable=true
        ./kafka-topics.sh --delete --topic my-topic --bootstrap-server host:9092 - удалить топик my-topic

Producer
    создать сообщение через CLI
        ./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic mytopic
        далее переходим в интеррактивный режим - пишем через терминал сообщения + Enter в my-topic
            >hello
             сообщение
        --property "parse.key=true" --property "key.separator=:"    свойства для попадания сообщения в
            >huid:hello                                             определённые разделы, проискодит
             ключ:сообщение                                         парсинг ключа по разделителю ':'
                                                                    либо любого другого
    разработка Java Producer - это Spring Boot приложение(микросервис)
    что должен делать producer:
        1. publish   - публикация событий на Kafka Broker
        2. serialize - сериализовать сообщение под нужный тип данных, также можно сериализовать
                       ключ под его тип данных. Например String для ключа, JSON для сообщения
        3. определять топик
        4. определять раздел(партицию)(если передается ключ)
    Можно отправлять сообщения в Kafka как синхронные(ждать подтверждения с Kafrf Broker)
    так и асинхронные(не ждать подтверждения, а слать сообщения, а при приходе подтверждения - обработать)
        Browser Mobile
               ^
         login | HTTP-request/responce
               v
        Auth Mecroservice       отправка
               ^ Kafka Template --------------> Kafka
               |  (Producer)    <-------------- Broker
               |                подтверждение
               v
            Database

Spring Boot Producer
    maven: 
        Spring Web
        Spring for Apache Kafka
    application.properties
        server.port=0 - автоматический порт(иначе 8080 может быть занят)
        spring.kafka.producer.bootstrap-servers=localhost:9092,localhost:9094 - брокеры(можно минимум 2)
        spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer         - серилизатор ключа
        spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer  - серилизатор сообщ
    KafkaConfig.java
        @Configuration
        public class KafkaConfig {

            @Bean
            NewTopic createTopic() {                                    // создает топик если его нет
                return TopicBuilder.name("product-created-event")       // топик
                        .partitions(3)                                  // кол-во пратиций
                        .replicas(3)                                    // кол-во реплик
                        .configs(Map.of("min.insync.replicas", "2"))    // минимум синхронизированных реплик с лидером
                        .build();
            }
        }

    ProductServiceImpl.java
        @Service
        public class ProductServiceImpl implements ProductService {
            @Autowired
            private KafkaTemplate<String, ProductCreatedEvent> kafkaTemplate;
            @Autowired
            private ProductRepository productRepository;

            @Override
            public String createProduct(MyDTO myDTO) {
                String productId = productRepository.save(myDTO);
                ProductCreatedEvent productCreatedEvent = new ProductCreatedEvent(productId,
                        myDTO.getTitle(),
                        myDTO.getPrice(),
                        myDTO.getQuantity());

                // асинхронная отправка
                CompletableFuture<SendResult<String, ProductCreatedEvent>> future =
                        kafkaTemplate.send("product-created-event", productId, productCreatedEvent);
        
                future.whenComplete((result, exception) -> {
                   if (exception != null) {
                       logger.error("ERROR: {}", exception.getMessage());
                   } else {
                       logger.info("Ok: {}", result.getRecordMetadata());
                   }
                });

                // синхронная отправка(когда нужно дождаться ответа перед тем как послать след сообщение)
                try {
                    SendResult<String, ProductCreatedEvent> result = 
                        kafkaTemplate.send("product-created-event", productId, productCreatedEvent).get();
                    logger.info("Ok: {}", result.getRecordMetadata());
                } catch (InterruptedException | ExecutionException e) {
                    logger.error("ERROR: {}", e.getMessage());
                }

                return productId;



        
