Apache Kafka
    Системы обмена сообщениями по принципу «публикация/подписка»
    Распределенный журнал фиксации транзакций
    Распределенная платформа потоковой обработки
    
    Данные в Kafka хранятся долго, упорядоченно, доступны для чтения,
    могут использоваться для доп защиты от сбоев и ради повышения
    производительности.


Паттерн публикация/подписка 
    publish/subscribe (pub/sub) messaging
    отправитель(издатель) элемента данных(сообщения) направляет это сообщение
    не конретно потребителю(подписчику), а просто классифицирует сообщение.
    Потребитель(подписчик) подписывается на определенные классы сообщений.
    Брокер - центральный пункт публикации сообщений, включен для упрощения
    взаимодействий между издателем и подписчиком.

Сообщения/event и пакеты
    message - сообщение [массив байтов] которой включает несколько атрибутов  
    event   - JSON String null - само так сказать тело сообщения
    key     - доп метаданные в сообщении, используется при
              необходимости лучше управлять записью сообщений в разделы
    offset  - доп метаданные в сообщении - непрерывно
              возрастающее int значение, смещение
    batch   - пакет/набор сообщений, относящихся к одному топику и разделу, 
              применяется для большей эффективности

Схемы
    Доп структура для сообщений, позволяет легко разбирать сообщения

Топики и разделы/Topic/Partition
    Топик   - сообщения в Kafka распределяются по топикам
    Раздел  - топики, в свою очередь, разбиваются на разделы(партиции)
    Stream  - поток данных, термин используется в рассмотрении топика

                Топик
    Раздел_0  0 1 2 3 4 5 6 7 8 9 10 <----------┐
    Раздел_1  0 1 2 3 4 5 6 7 8 9 <-------------┤
    Раздел_2  0 1 2 3 4 5 6 7 8 9 10 12 13 <----┤--- операция записи
    Раздел_3  0 1 2 3 4 5 6 7 8 9 10 12 13 14 <-┤
    Раздел_4  0 1 2 3 4 5 6 7 <-----------------┘

    после записи сообщения нельзя изменить/удалить

    Если записывать в один раздел, то очередность чтения сохраниться,
    иначе чтение сообщений происходит параллельно

Производители и потребители
    producer    - publisher/writer/производитель, генерирует нов сообщения
                  сообщения создаются для конкретного топика, по умолчанию
                  производитель будет равномерно поставлять сообщения во 
                  все разделы топика, но может в конкретный раздел, 
                  используя ключ.
    consumer    - subscriber/reader/потребитель читает сообщения.
                  Потребитель подписывается на один или более топиков и 
                  читает сообщения в порядке их создания в каждом разделе,
                  отслеживает какие сообщения были прочитаны, запоминая
                  смещение(offset), может приостанавливать и возобновлять
                  чтение благодаря этому.
    consumer groups
                - один или нескольких потребителей, объединившихся для 
                  обработки топика в группу. Организация в группы гарантирует 
                  чтение каждого раздела только одним членом группы

Брокеры и кластеры
    Broker_1    Broker_2    Broker_3        Пример 3 брокера, 2 топика по 3 партиции:
                                            1 брокер - лидер для partition_10 и partition_22
        Topic_1         Topic_2                        фолловер для partition_11 partition_12
        partition_10    partition_20                                partition_20 partition_21
        partition_11    partition_21        2 брокер - лидер для partition_11 и partition_21
        partition_12    partition_22                   фолловер для partition_10 partition_12
                                                                    partition_20 partition_22
                                            3 брокер - лидер для partition_12 и partition_20
                                                       фолловер для partition_10 partition_11
                                                                    partition_21 partition_22

    При падении одного из брокеров, если он был лидером - лидер назначается из фолловеров

    broker  - отдельный сервер Kafka - получает сообщения от производителей, 
              присваивает им смещения и записывает сообщения в дисковое 
              хранилище. Он также обслуживает потребители и отвечает на запросы
              выборки из разделов, возвращая опубликованные сообщения
    cluster - Брокеры Kafka предназначены для работы в составе кластера
    cluster controller 
            - контроллер, один из брокеров кластера, выбирается автоматически 
              из числа работающих членов кластера. Отвечает за административные
              операции, включая распределение разделов по брокерам, мониторинг
    leader  - ведущий брокер, которому принадлежит раздел, для каждого раздела,
              соединяется с producer для публикации сообщений, consumer также
              может получать сообщения с ведущего
    follower- брокер-последователь, которому принадлежит реплицированный
              (дублирующий) раздел от ведущего. consumer также может получать 
              сообщения с последователя
    настройки 
            - В настройки брокеров Kafka включается длительность хранения 
              топиков по умолчанию - или в течение определенного промежутка 
              времени (например, семь дней), или до достижения разделом
              определенного размера в байтах (например, 1 Гбайт). 
              Превысившие эти пределы сообщения становятся недействительными и 
              удаляются
    
    Обычно на один раздел топика вешаются 3 брокера, 1 лидер + 2 последователя
    А один брокер берет один раздел как лидер и два как последователь
    Количество разделов должно быть >= кол-во consumers

Почему Kafka
    Несколько производителей    - способность работать с несколькими производителями
                                  вне зависимости от того, используют они один топик
                                  или несколько
    Несколько потребителей      - способность читать любой один поток сообщений, не 
                                  мешая друг другу
    Сохранение информ на диске  - потребители не обязательно должны работать в режиме
                                  реального времени
    Масштабируемость            - любые объемы данных
    ...


Install
    Java      - 8+
    ZooKeeper - Apache ZooKeeper это централизованный сервис для хранения информации 
                о конфигурации, присвоения имен, обеспечения распределенной 
                синхронизации и предоставления группового обслуживания.
                Используется для хранения метаданных о кластере Kafka
                zoo.cfg - файл конфиг ZooKeeper
                myid    - id сервера, в zoo.cfg можно указывать ансамбль серверов
    KRaft     - протокол пришел на смену ZooKeeper, замена Zookeeper в роли хранилища
                метаданных, с целью упрощения развертывания Kafka-кластера, внутри
                пакета Kafka лежат конфиги KRaft
                config/kraft      - дир с настройками KRaft
                broker.properties - конфиг сервера, который действует как брокер,
                                    настройка топиков, разделов
                controller.prop   - конфиг сервера, который действует как контроллер
                                    управляет метадаными кластера, управляет лидерами
                server.properties - конфиг сервера, который и контроллер и брокер                
    Kafka     - брокер кафка
                broker.id - id брокера в пределах кластера
                Listeners - разделенный запятыми список URI
                zookeeper.connect - ZooKeeper(hostname, port, path)
                log.dirs - куда пишутся все сообщения
                num.partitions - кол-во разделов
                log.retention.ms - время хранения сообщений
                log.retention.bytes - кол-во мас хранимых байтов


Event-Driven Architecture
                                        consumers:
                                        Email-micro
     producer                         /
    Payment-micro --publish--> Topic <- SMS-micro
                                      \
                                        Push-micro

    все работает асинхронно
    если допустим Push-micro не успевает обрабатывать сообщения Kafka
    то можно просто создать consumer groups из таких одинаковых  сервисов Push-micro


Kafka CLI
    command line interface - работа с kafka через терминал
    просто запускаем скрипты из директории bin


Запуск 1 сервера Kafka
    bin                                 - директория со скриптами
    ./kafka-storage.sh random-uuid      - сгенерить id для kafka кластера
    ./kafka-storage.sh format -t <uuid> -c ../config/kraft/server.properties - формат логов
    ./kafka-server-start.sh ../config/kraft/server.properties                - старт сервера


Запуск на нескольких серверах
    создать файлы аналогичные config/kraft/server.properties под сервера
    изменяем в каждом файле:
        node.id     - id сервера в Kafka кластере, делаем уникальные для каждого сервера
        listeners   - список адрес:портов которые слушает kafka
                      поменять для каждого сервера порты:
                      PLAINTEXT://9092  - брокер
                      CONTROLLER://9093 - контроллер
                      следующий сервер допустим 9094 9095 и тд
        controller.quorum.votes
                    - управление лидерами, последователями при падениях серверов
                      1@localhost:9093  - id_сервера@url_контроллера
                      для трёх серверов будет так во всех файлах:
                      1@localhost:9093,2@localhost:9095,3@localhost:9097
        advertused.listeners
                    - список адресов брокеров, может совпадать или быть другим для
                      клиентов, например внешним, далее соединяется с внутринним listeners
                      PLAINTEXT://9092 выставить во всех файлах свой порт если совпадает с 
                      listeners, либо какой-то свой url
        log.dirs    - директория для логов
                      меняем для каждого сервера свою директорию
                      /tmp/serv1/kraft-combined-logs
    запуск серверов:
        генерим uuid:
            ./kafka-storage.sh random-uuid - сгенерим id кластера IuLotyvvS-GX5jpwmZYXeQ
        формат логов для совместимости:
            ./kafka-storage.sh format -t IuLotyvvS-GX5jpwmZYXeQ -c ../config/kraft/serv1
            ./kafka-storage.sh format -t IuLotyvvS-GX5jpwmZYXeQ -c ../config/kraft/serv2
            ./kafka-storage.sh format -t IuLotyvvS-GX5jpwmZYXeQ -c ../config/kraft/serv3
        запуск серверов(в разных терминалах):
            ./kafka-server-start.sh ../config/kraft/serv1
            ./kafka-server-start.sh ../config/kraft/serv2
            ./kafka-server-start.sh ../config/kraft/serv3


Остановка сервера
    Не останавливаем ctrl+c(портеря данных, логи ...)
    1. останановка produsers, consumers
    2. остановка с пом терминала ./kafka-server-stop.sh


Topic
    создать новый топик:
        запустить сервера
        ./kafka-topics.sh --create                                  создать  
                          --topic my-topic                          топик с именем my-topic
                          --partitions 3                            разделы количество, лучше делать
                                                                    >= кол-ва consumers, иначе парал-
                                                                    лельного чтения не будет
                          --replication-factor 3                    кол-во копий каждого раздела <= кол-во серверов
                                                                    одна в лидере +остальные в
                                                                    репликах лучше делать = кол-во серверов
                          --bootstrap-server host:9092,host:9094    список брокеров в кластере, рекомендуется
                                                                    указывать хотя бы 2(один мало, вдруг недоступен)
    посмотреть топики:
        ./kafka-topics.sh --list --bootstrap-server host:9092       посмотреть топики, указываем один
                                                                    из брокеров кластера
        ./kafka-topics.sh --describe --bootstrap-server host:9092   детальная информация о топиках
                                                                    partition : 0   - раздел
                                                                    Leader: 1       - лидер раздела
                                                                    Replicas: 1,2,3 - копии на серверах
                                                                    Isr: 1,2,3      - синхронизация серверов
    изменить топик:
        изменить количество разделов
        kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic --partitions 16
    удалить топик:
        включить настройку, если выключена delete.topic.enable=true
        ./kafka-topics.sh --delete --topic my-topic --bootstrap-server host:9092 - удалить топик my-topic

Producer
    создать сообщение через CLI
        ./kafka-console-producer.sh --bootstrap-server localhost:9092 
                                    --topic mytopic                 топик в который будем публиковать
        далее переходим в интеррактивный режим - пишем через терминал сообщения + Enter в my-topic
            >hello
             сообщение              
                                    --property "parse.key=true"     свойства для попадания сообщения в
                                    --property "key.separator=:"    парсинг ключа по разделителю ':'
            >huid:hello                                             либо любого другого
             ключ:сообщение                                         
                                                                    
    разработка Java Producer - это Spring Boot приложение(микросервис)
    что должен делать producer:
        1. publish   - публикация событий на Kafka Broker
        2. serialize - сериализовать сообщение под нужный тип данных, также можно сериализовать
                       ключ под его тип данных. Например String для ключа, JSON для сообщения
        3. определять топик
        4. определять раздел(партицию)(если передается ключ)
    Можно отправлять сообщения в Kafka как синхронные(ждать подтверждения с Kafka Broker)
    так и асинхронные(не ждать подтверждения, а слать сообщения, а при приходе подтверждения - обработать)
        Browser Mobile
               ^
         login | HTTP-request/responce
               v
        Auth Mecroservice       отправка
               ^ Kafka Template --------------> Kafka
               |  (Producer)    <-------------- Broker
               |                подтверждение
               v
            Database

Spring Boot Producer
    maven: 
        Spring Web
        Spring for Apache Kafka
    application.properties
        server.port=0
        spring.kafka.producer.bootstrap-servers=localhost:9092,localhost:9094
        spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
        spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
        spring.kafka.producer.acks=all
        spring.kafka.producer.retries=10
        spring.kafka.producer.properties.retry.backoff.ms=1000
        spring.kafka.producer.properties.delivery.timeout.ms=20000
        spring.kafka.producer.properties.linger.ms=0
        spring.kafka.producer.properties.request.timeout.ms=10000
        spring.kafka.producer.properties.max.in.flight.requests.per.connection=5
        spring.kafka.producer.properties.enable.idempotence=true
    KafkaConfig.java
        @Configuration
        public class KafkaConfig {

            @Bean
            NewTopic createTopic() {                                    // создает топик если его нет
                return TopicBuilder.name("product-created-event")       // топик
                        .partitions(3)                                  // кол-во пратиций
                        .replicas(3)                                    // кол-во реплик
                        .configs(Map.of("min.insync.replicas", "2"))    // минимум синхронизированных реплик с лидером
                        .build();
            }

            // есть ещё один вариант конфига kafkaTemplate более гибкий
            // прокидываем все пропертя в переменные
            @Value("${spring.kafka.producer.bootstrap-servers}")
            private String bootstrapServers;
            @Value("${spring.kafka.producer.key-serializer}")
            private String keySerializer;

            // создаем мэпку(получение с пом метода)
            private Map<String, Object> producerConfig() {
                Map<String, Object> config = new HashMap<>();
                config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
                config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, keySerializer);
                return config;
            }

            // создаем 2 бина: фабрику и kafkaTemplate
            @Bean
            ProducerFactory<String, ProductCreatedEvent> producerFactory() {
                return new DefaultKafkaProducerFactory<>(producerConfig());
            }

            @Bean
            KafkaTemplate<String, ProductCreatedEvent> kafkaTemplate() {
                return new KafkaTemplate<>(producerFactory());
            }
        }

    ProductServiceImpl.java
        @Service
        public class ProductServiceImpl implements ProductService {
            @Autowired
            private KafkaTemplate<String, ProductCreatedEvent> kafkaTemplate;
            @Autowired
            private ProductRepository productRepository;

            @Override
            public String createProduct(MyDTO myDTO) {
                String productId = productRepository.save(myDTO);
                ProductCreatedEvent productCreatedEvent = new ProductCreatedEvent(productId,
                        myDTO.getTitle(),
                        myDTO.getPrice(),
                        myDTO.getQuantity());

                // асинхронная отправка
                CompletableFuture<SendResult<String, ProductCreatedEvent>> future =
                        kafkaTemplate.send("product-created-event", productId, productCreatedEvent);
        
                future.whenComplete((result, exception) -> {
                   if (exception != null) {
                       logger.error("ERROR: {}", exception.getMessage());
                   } else {
                       logger.info("Ok: {}", result.getRecordMetadata());
                   }
                });

                // синхронная отправка(когда нужно дождаться ответа перед тем как послать след сообщение)
                SendResult<String, ProductCreatedEvent> result = 
                    kafkaTemplate.send("product-created-event", productId, productCreatedEvent).get();
                logger.info("Ok: {}", result.getRecordMetadata());

                return productId;

Получение acknowledgment
    Варианты конфигурации:
        1. Ждать acknowledgement от всех insync реплик  - spring.kafka.producer.acks=all
        2. Не получать acknowledgement                  - spring.kafka.producer.acks=0
        3. Получать только от Leader(default)           - spring.kafka.producer.acks=1
    Если acknowledgment не приходит от лидера или при all не приходит от всех insync реплик, 
    то Producer начинает делать retry:
        Либо делает retry в течение 2 мин, либо делаем максимальное кол-во retry 2147483647, либо указываем
        вручную кол-во retry, интервал, время попыток:
            spring.kafka.producer.retries=10 (default 2147483647 максимальное кол-во retry)
            spring.kafka.producer.properties.retry.backoff.ms=1000  (default 100 интервал отправки сообщений)
            spring.kafka.producer.properties.delivery.timeout.ms=60000 (default 120000 время попыток)
            spring.kafka.producer.properties.linger.ms=0 (сколько по времени накапливаем сообщ, потом шлем батчем)
            spring.kafka.producer.properties.request.timeout.ms=30000 (как долго prducer ждет ответа от брокера)
            spring.kafka.producer.properties.max.in.flight.requests.per.connection=5 (макс 5 сообщений без ответа)
            spring.kafka.producer.properties.enable.idempotence=true (Idempotent Producer - ниже описано)
            !!! delivery.timeout.ms >= linger.ms + request.timeout.ms
    Ошибки типа error acknowlegement:
        1. Retryable error - временная проблема, может быть решена повтором(retry), если
           например реплика упала
        2. Non-Retryable error - постоянная ошибка - не может быть решена повтором, если
           например превышен допустимый размер сообщения

Idempotent Producer
    При послылке сообщения и сохранении его в топик, допустим валится acknowledgment
    Делается retry но сообщение НЕ сохраняется ещё раз, а возвращается acknowledgment
    по умолчанию true, но рекумендуется указать явно 
    включить конфиг через properties или мэпку
        spring.kafka.producer.properties.enable.idempotence=true
        config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true)


Consumer
    Прочитать сообщение с помощью CLI
        ./kafka-console-consumer.sh 
            --bootstrap-server localhost:9092,localhost:9094    сервера
            --topic mytopic                                     топик для чтения
            --from-beginning                                    печать все сообщения сначала
            --property "print.key=true"                         печатать ключ и сообщение
        
Spring Boot Consumer
    Producer ---------> Broker: Topic[][][][] ---------> Consumer
              publish      store               consume
    
    Если Consumer один - то чтение идет с разных разделов
    Если сделать 3 реплики Consumer - то в случае если разделов 3 - читать будет каждый 1 раздел
    Это называется ConsumerGroup

    properties:
        server.port=0
        spring.kafka.consumer.bootstrap-servers=localhost:9092,localhost:9094
        spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
        spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
        spring.kafka.consumer.group-id=product-created-events           - уникальный group id consumer
        spring.kafka.consumer.properties.spring.json.trusted.packages=* - доверенные пакеты(* - все)

    KafkaConfig.java
    @Configuration
    public class KafkaConfig {
        @Autowired
        Environment environment;

        @Bean
        ConsumerFactory<String, Object> consumerFactory () {
            Map<String, Object> config = new HashMap<>();
            config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, environment.getProperty("spring.kafka.consumer.bootstrap-servers"));
            config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
            config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer.class); // скипает SerializationException
                                                                                                            если допустим пришла строка, выскакивает
                                                                                                            SerializationException 1 раз и пропускается
                                                                                                            переходит к следующей ячейке
            config.put(ErrorHandlingDeserializer.VALUE_DESERIALIZER_CLASS, JsonDeserializer.class);      // обрабатывает JSON
            config.put(ConsumerConfig.GROUP_ID_CONFIG, environment.getProperty("spring.kafka.consumer.group-id"));
            config.put(JsonDeserializer.TRUSTED_PACKAGES, environment.getProperty("spring.kafka.consumer.properties.spring.json.trusted.packages"));

            return new DefaultKafkaConsumerFactory<>(config);
        }

        @Bean
        ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(ConsumerFactory<String, Object> consumerFactory) {
            ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
            factory.setConsumerFactory(consumerFactory);

            return factory;
        }
    }